---
# Smart Librarian Export (v2.0)
- Page Number: 18
- Timestamp: 2025-12-14T14:59:18.950805+02:00
- Source URL: https://docs.pydantic.dev/latest/concepts/types
- Page Title: Types - Pydantic Validation
- Semantic Filename: types_pydantic_validation.md
- Ollama Model: llama3.2:3b
- Export Mode: Smart Deep Crawl
- Statistics:
  - Status: Success
  - Content Length: 38,339 characters
---

# Types - Pydantic Validation

[ Skip to content ](https://docs.pydantic.dev/latest/concepts/types/#custom-types)
What's new â€” we've launched [Pydantic Logfire](https://pydantic.dev/articles/logfire-announcement) ![ðŸ”¥](https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.0.3/assets/svg/1f525.svg) to help you monitor and understand your [Pydantic validations.](https://logfire.pydantic.dev/docs/integrations/pydantic/)
# Types
Pydantic uses types to define how validation and serialization should be performed. [Built-in and standard library types](https://docs.pydantic.dev/latest/api/standard_library_types/) (such as [Strictness](https://docs.pydantic.dev/latest/concepts/strict_mode/) can be controlled and constraints can be applied on them.
On top of these, Pydantic provides extra types, either [directly in the library](https://docs.pydantic.dev/latest/api/types/) (e.g. [`SecretStr`](https://docs.pydantic.dev/latest/api/types/#pydantic.types.SecretStr)) or in the [custom types](https://docs.pydantic.dev/latest/concepts/types/#custom-types) section. Strictness and constraints _can't_ be applied on them.
The [built-in and standard library types](https://docs.pydantic.dev/latest/api/standard_library_types/) documentation goes over the supported types: the allowed values, the possible validation constraints, and whether [strictness](https://docs.pydantic.dev/latest/concepts/strict_mode/) can be configured.
See also the [conversion table](https://docs.pydantic.dev/latest/concepts/conversion_table/) for a summary of the allowed values for each type.
This page will go over defining your own custom types.
## Custom Types[Â¶](https://docs.pydantic.dev/latest/concepts/types/#custom-types)
There are several ways to define your custom types.
### Using the annotated pattern[Â¶](https://docs.pydantic.dev/latest/concepts/types/#using-the-annotated-pattern)
The [annotated pattern](https://docs.pydantic.dev/latest/concepts/fields/#the-annotated-pattern) can be used to make types reusable across your code base. For example, to create a type representing a positive integer:
```
fromtypingimport Annotated

frompydanticimport Field, TypeAdapter, ValidationError

PositiveInt = Annotated[int, Field(gt=0)]  [](https://docs.pydantic.dev/latest/concepts/types/#__code_0_annotation_1)

ta = TypeAdapter(PositiveInt)

print(ta.validate_python(1))
#> 1

try:
    ta.validate_python(-1)
except ValidationError as exc:
    print(exc)
"""
    1 validation error for constrained-int
      Input should be greater than 0 [type=greater_than, input_value=-1, input_type=int]
    """

```

#### Adding validation and serialization[Â¶](https://docs.pydantic.dev/latest/concepts/types/#adding-validation-and-serialization)
You can add or override validation, serialization, and JSON schemas to an arbitrary type using the markers that Pydantic exports:
```
fromtypingimport Annotated

frompydanticimport (
    AfterValidator,
    PlainSerializer,
    TypeAdapter,
    WithJsonSchema,
)

TruncatedFloat = Annotated[
    float,
    AfterValidator(lambda x: round(x, 1)),
    PlainSerializer(lambda x: f'{x:.1e}', return_type=str),
    WithJsonSchema({'type': 'string'}, mode='serialization'),
]


ta = TypeAdapter(TruncatedFloat)

input = 1.02345
assert input != 1.0

assert ta.validate_python(input) == 1.0

assert ta.dump_json(input) == b'"1.0e+00"'

assert ta.json_schema(mode='validation') == {'type': 'number'}
assert ta.json_schema(mode='serialization') == {'type': 'string'}

```

#### Generics[Â¶](https://docs.pydantic.dev/latest/concepts/types/#generics)
```
fromtypingimport Annotated, TypeVar

fromannotated_typesimport Gt, Len

frompydanticimport TypeAdapter, ValidationError

T = TypeVar('T')


ShortList = Annotated[list[T], Len(max_length=4)]


ta = TypeAdapter(ShortList[int])

v = ta.validate_python([1, 2, 3, 4])
assert v == [1, 2, 3, 4]

try:
    ta.validate_python([1, 2, 3, 4, 5])
except ValidationError as exc:
    print(exc)
"""
    1 validation error for list[int]
      List should have at most 4 items after validation, not 5 [type=too_long, input_value=[1, 2, 3, 4, 5], input_type=list]
    """


PositiveList = list[Annotated[T, Gt(0)]]

ta = TypeAdapter(PositiveList[float])

v = ta.validate_python([1.0])
assert type(v[0]) is float


try:
    ta.validate_python([-1.0])
except ValidationError as exc:
    print(exc)
"""
    1 validation error for list[constrained-float]
    0
      Input should be greater than 0 [type=greater_than, input_value=-1.0, input_type=float]
    """

```

### Named type aliases[Â¶](https://docs.pydantic.dev/latest/concepts/types/#named-type-aliases)
The above examples make use of _implicit_ type aliases, assigned to a variable. At runtime, Pydantic has no way of knowing the name of the variable it was assigned to, and this can be problematic for two reasons:
  * The [JSON Schema](https://docs.pydantic.dev/latest/concepts/json_schema/) of the alias won't be converted into a 
  * In most cases, [recursive type aliases](https://docs.pydantic.dev/latest/concepts/types/#named-recursive-types) won't work.


By leveraging the new 
[Python 3.9 and above](https://docs.pydantic.dev/latest/concepts/types/#__tabbed_1_1)[Python 3.12 and above (new syntax)](https://docs.pydantic.dev/latest/concepts/types/#__tabbed_1_2)
```
fromtypingimport Annotated

fromannotated_typesimport Gt
fromtyping_extensionsimport TypeAliasType

frompydanticimport BaseModel

PositiveIntList = TypeAliasType('PositiveIntList', list[Annotated[int, Gt(0)]])


classModel(BaseModel):
    x: PositiveIntList
    y: PositiveIntList


print(Model.model_json_schema())  [](https://docs.pydantic.dev/latest/concepts/types/#__code_3_annotation_1)
"""
{
    '$defs': {
        'PositiveIntList': {
            'items': {'exclusiveMinimum': 0, 'type': 'integer'},
            'type': 'array',
        }
    },
    'properties': {
        'x': {'$ref': '#/$defs/PositiveIntList'},
        'y': {'$ref': '#/$defs/PositiveIntList'},
    },
    'required': ['x', 'y'],
    'title': 'Model',
    'type': 'object',
}
"""

```

```
fromtypingimport Annotated

fromannotated_typesimport Gt

frompydanticimport BaseModel

type PositiveIntList = list[Annotated[int, Gt(0)]]


classModel(BaseModel):
    x: PositiveIntList
    y: PositiveIntList


print(Model.model_json_schema())  [](https://docs.pydantic.dev/latest/concepts/types/#__code_4_annotation_1)
"""
{
    '$defs': {
        'PositiveIntList': {
            'items': {'exclusiveMinimum': 0, 'type': 'integer'},
            'type': 'array',
        }
    },
    'properties': {
        'x': {'$ref': '#/$defs/PositiveIntList'},
        'y': {'$ref': '#/$defs/PositiveIntList'},
    },
    'required': ['x', 'y'],
    'title': 'Model',
    'type': 'object',
}
"""

```

  1. If `PositiveIntList` were to be defined as an implicit type alias, its definition would have been duplicated in both `'x'` and `'y'`.


[](https://docs.pydantic.dev/latest/concepts/types/)
When to use named type aliases
While (named) PEP 695 and implicit type aliases are meant to be equivalent for static type checkers, Pydantic will _not_ understand field-specific metadata inside named aliases. That is, metadata such as `alias`, `default`, `deprecated`, _cannot_ be used:
[Python 3.9 and above](https://docs.pydantic.dev/latest/concepts/types/#__tabbed_2_1)[Python 3.12 and above (new syntax)](https://docs.pydantic.dev/latest/concepts/types/#__tabbed_2_2)
```
fromtypingimport Annotated

fromtyping_extensionsimport TypeAliasType

frompydanticimport BaseModel, Field

MyAlias = TypeAliasType('MyAlias', Annotated[int, Field(default=1)])


classModel(BaseModel):
    x: MyAlias  # This is not allowed

```

```
fromtypingimport Annotated

frompydanticimport BaseModel, Field

type MyAlias = Annotated[int, Field(default=1)]


classModel(BaseModel):
    x: MyAlias  # This is not allowed

```

Only metadata that can be applied to the annotated type itself is allowed (e.g. [validation constraints](https://docs.pydantic.dev/latest/concepts/fields/#field-constraints) and JSON metadata). Trying to support field-specific metadata would require eagerly inspecting the type alias's 
Note
As with implicit type aliases, 
[Python 3.9 and above](https://docs.pydantic.dev/latest/concepts/types/#__tabbed_3_1)[Python 3.12 and above (new syntax)](https://docs.pydantic.dev/latest/concepts/types/#__tabbed_3_2)
```
fromtypingimport Annotated, TypeVar

fromannotated_typesimport Len
fromtyping_extensionsimport TypeAliasType

T = TypeVar('T')

ShortList = TypeAliasType(
    'ShortList', Annotated[list[T], Len(max_length=4)], type_params=(T,)
)

```

```
fromtypingimport Annotated, TypeVar

fromannotated_typesimport Len

type ShortList[T] = Annotated[list[T], Len(max_length=4)]

```

#### Named recursive types[Â¶](https://docs.pydantic.dev/latest/concepts/types/#named-recursive-types)
Named type aliases should be used whenever you need to define recursive type aliases 
For instance, here is an example definition of a JSON type:
[Python 3.9 and above](https://docs.pydantic.dev/latest/concepts/types/#__tabbed_4_1)[Python 3.12 and above (new syntax)](https://docs.pydantic.dev/latest/concepts/types/#__tabbed_4_2)
```
fromtypingimport Union

fromtyping_extensionsimport TypeAliasType

frompydanticimport TypeAdapter

Json = TypeAliasType(
    'Json',
    'Union[dict[str, Json], list[Json], str, int, float, bool, None]',  [](https://docs.pydantic.dev/latest/concepts/types/#__code_9_annotation_1)
)

ta = TypeAdapter(Json)
print(ta.json_schema())
"""
{
    '$defs': {
        'Json': {
            'anyOf': [
                {
                    'additionalProperties': {'$ref': '#/$defs/Json'},
                    'type': 'object',
                },
                {'items': {'$ref': '#/$defs/Json'}, 'type': 'array'},
                {'type': 'string'},
                {'type': 'integer'},
                {'type': 'number'},
                {'type': 'boolean'},
                {'type': 'null'},
            ]
        }
    },
    '$ref': '#/$defs/Json',
}
"""

```

```
frompydanticimport TypeAdapter

type Json = dict[str, Json] | list[Json] | str | int | float | bool | None  [](https://docs.pydantic.dev/latest/concepts/types/#__code_10_annotation_1)

ta = TypeAdapter(Json)
print(ta.json_schema())
"""
{
    '$defs': {
        'Json': {
            'anyOf': [
                {
                    'additionalProperties': {'$ref': '#/$defs/Json'},
                    'type': 'object',
                },
                {'items': {'$ref': '#/$defs/Json'}, 'type': 'array'},
                {'type': 'string'},
                {'type': 'integer'},
                {'type': 'number'},
                {'type': 'boolean'},
                {'type': 'null'},
            ]
        }
    },
    '$ref': '#/$defs/Json',
}
"""

```

  1. The value of a named type alias is lazily evaluated, so there's no need to use forward annotations.


Tip
Pydantic defines a [`JsonValue`](https://docs.pydantic.dev/latest/api/types/#pydantic.types.JsonValue) type as a convenience.
### Customizing validation with `__get_pydantic_core_schema__` [Â¶](https://docs.pydantic.dev/latest/concepts/types/#customizing-validation-with-__get_pydantic_core_schema__)
To do more extensive customization of how Pydantic handles custom classes, and in particular when you have access to the class or can subclass it, you can implement a special `__get_pydantic_core_schema__` to tell Pydantic how to generate the `pydantic-core` schema.
While `pydantic` uses `pydantic-core` internally to handle validation and serialization, it is a new API for Pydantic V2, thus it is one of the areas most likely to be tweaked in the future and you should try to stick to the built-in constructs like those provided by `annotated-types`, `pydantic.Field`, or `BeforeValidator` and so on.
You can implement `__get_pydantic_core_schema__` both on a custom type and on metadata intended to be put in `Annotated`. In both cases the API is middleware-like and similar to that of "wrap" validators: you get a `source_type` (which isn't necessarily the same as the class, in particular for generics) and a `handler` that you can call with a type to either call the next metadata in `Annotated` or call into Pydantic's internal schema generation.
The simplest no-op implementation calls the handler with the type you are given, then returns that as the result. You can also choose to modify the type before calling the handler, modify the core schema returned by the handler, or not call the handler at all.
#### As a method on a custom type[Â¶](https://docs.pydantic.dev/latest/concepts/types/#as-a-method-on-a-custom-type)
The following is an example of a type that uses `__get_pydantic_core_schema__` to customize how it gets validated. This is equivalent to implementing `__get_validators__` in Pydantic V1.
```
fromtypingimport Any

frompydantic_coreimport CoreSchema, core_schema

frompydanticimport GetCoreSchemaHandler, TypeAdapter


classUsername(str):
    @classmethod
    def__get_pydantic_core_schema__(
        cls, source_type: Any, handler: GetCoreSchemaHandler
    ) -> CoreSchema:
        return core_schema.no_info_after_validator_function(cls, handler(str))


ta = TypeAdapter(Username)
res = ta.validate_python('abc')
assert isinstance(res, Username)
assert res == 'abc'

```

See [JSON Schema](https://docs.pydantic.dev/latest/concepts/json_schema/) for more details on how to customize JSON schemas for custom types.
#### As an annotation[Â¶](https://docs.pydantic.dev/latest/concepts/types/#as-an-annotation)
Often you'll want to parametrize your custom type by more than just generic type parameters (which you can do via the type system and will be discussed later). Or you may not actually care (or want to) make an instance of your subclass; you actually want the original type, just with some extra validation done.
For example, if you were to implement `pydantic.AfterValidator` (see [Adding validation and serialization](https://docs.pydantic.dev/latest/concepts/types/#adding-validation-and-serialization)) yourself, you'd do something similar to the following:
[Python 3.9 and above](https://docs.pydantic.dev/latest/concepts/types/#__tabbed_5_1)[Python 3.10 and above](https://docs.pydantic.dev/latest/concepts/types/#__tabbed_5_2)
```
fromdataclassesimport dataclass
fromtypingimport Annotated, Any, Callable

frompydantic_coreimport CoreSchema, core_schema

frompydanticimport BaseModel, GetCoreSchemaHandler


@dataclass(frozen=True)  [](https://docs.pydantic.dev/latest/concepts/types/#__code_12_annotation_1)
classMyAfterValidator:
    func: Callable[[Any], Any]

    def__get_pydantic_core_schema__(
        self, source_type: Any, handler: GetCoreSchemaHandler
    ) -> CoreSchema:
        return core_schema.no_info_after_validator_function(
            self.func, handler(source_type)
        )


Username = Annotated[str, MyAfterValidator(str.lower)]


classModel(BaseModel):
    name: Username


assert Model(name='ABC').name == 'abc'  [](https://docs.pydantic.dev/latest/concepts/types/#__code_12_annotation_2)

```

```
fromdataclassesimport dataclass
fromtypingimport Annotated, Any
fromcollections.abcimport Callable

frompydantic_coreimport CoreSchema, core_schema

frompydanticimport BaseModel, GetCoreSchemaHandler


@dataclass(frozen=True)  [](https://docs.pydantic.dev/latest/concepts/types/#__code_13_annotation_1)
classMyAfterValidator:
    func: Callable[[Any], Any]

    def__get_pydantic_core_schema__(
        self, source_type: Any, handler: GetCoreSchemaHandler
    ) -> CoreSchema:
        return core_schema.no_info_after_validator_function(
            self.func, handler(source_type)
        )


Username = Annotated[str, MyAfterValidator(str.lower)]


classModel(BaseModel):
    name: Username


assert Model(name='ABC').name == 'abc'  [](https://docs.pydantic.dev/latest/concepts/types/#__code_13_annotation_2)

```

  1. The `frozen=True` specification makes `MyAfterValidator` hashable. Without this, a union such as `Username | None` will raise an error.
  2. Notice that type checkers will not complain about assigning `'ABC'` to `Username` like they did in the previous example because they do not consider `Username` to be a distinct type from `str`.


#### Handling third-party types[Â¶](https://docs.pydantic.dev/latest/concepts/types/#handling-third-party-types)
Another use case for the pattern in the previous section is to handle third party types.
```
fromtypingimport Annotated, Any

frompydantic_coreimport core_schema

frompydanticimport (
    BaseModel,
    GetCoreSchemaHandler,
    GetJsonSchemaHandler,
    ValidationError,
)
frompydantic.json_schemaimport JsonSchemaValue


classThirdPartyType:
"""
    This is meant to represent a type from a third-party library that wasn't designed with Pydantic
    integration in mind, and so doesn't have a `pydantic_core.CoreSchema` or anything.
    """

    x: int

    def__init__(self):
        self.x = 0


class_ThirdPartyTypePydanticAnnotation:
    @classmethod
    def__get_pydantic_core_schema__(
        cls,
        _source_type: Any,
        _handler: GetCoreSchemaHandler,
    ) -> core_schema.CoreSchema:
"""
        We return a pydantic_core.CoreSchema that behaves in the following ways:

        * ints will be parsed as `ThirdPartyType` instances with the int as the x attribute
        * `ThirdPartyType` instances will be parsed as `ThirdPartyType` instances without any changes
        * Nothing else will pass validation
        * Serialization will always return just an int
        """

        defvalidate_from_int(value: int) -> ThirdPartyType:
            result = ThirdPartyType()
            result.x = value
            return result

        from_int_schema = core_schema.chain_schema(
            [
                core_schema.int_schema(),
                core_schema.no_info_plain_validator_function(validate_from_int),
            ]
        )

        return core_schema.json_or_python_schema(
            json_schema=from_int_schema,
            python_schema=core_schema.union_schema(
                [
                    # check if it's an instance first before doing any further work
                    core_schema.is_instance_schema(ThirdPartyType),
                    from_int_schema,
                ]
            ),
            serialization=core_schema.plain_serializer_function_ser_schema(
                lambda instance: instance.x
            ),
        )

    @classmethod
    def__get_pydantic_json_schema__(
        cls, _core_schema: core_schema.CoreSchema, handler: GetJsonSchemaHandler
    ) -> JsonSchemaValue:
        # Use the same schema that would be used for `int`
        return handler(core_schema.int_schema())


# We now create an `Annotated` wrapper that we'll use as the annotation for fields on `BaseModel`s, etc.
PydanticThirdPartyType = Annotated[
    ThirdPartyType, _ThirdPartyTypePydanticAnnotation
]


# Create a model class that uses this annotation as a field
classModel(BaseModel):
    third_party_type: PydanticThirdPartyType


# Demonstrate that this field is handled correctly, that ints are parsed into `ThirdPartyType`, and that
# these instances are also "dumped" directly into ints as expected.
m_int = Model(third_party_type=1)
assert isinstance(m_int.third_party_type, ThirdPartyType)
assert m_int.third_party_type.x == 1
assert m_int.model_dump() == {'third_party_type': 1}

# Do the same thing where an instance of ThirdPartyType is passed in
instance = ThirdPartyType()
assert instance.x == 0
instance.x = 10

m_instance = Model(third_party_type=instance)
assert isinstance(m_instance.third_party_type, ThirdPartyType)
assert m_instance.third_party_type.x == 10
assert m_instance.model_dump() == {'third_party_type': 10}

# Demonstrate that validation errors are raised as expected for invalid inputs
try:
    Model(third_party_type='a')
except ValidationError as e:
    print(e)
"""
    2 validation errors for Model
    third_party_type.is-instance[ThirdPartyType]
      Input should be an instance of ThirdPartyType [type=is_instance_of, input_value='a', input_type=str]
    third_party_type.chain[int,function-plain[validate_from_int()]]
      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='a', input_type=str]
    """


assert Model.model_json_schema() == {
    'properties': {
        'third_party_type': {'title': 'Third Party Type', 'type': 'integer'}
    },
    'required': ['third_party_type'],
    'title': 'Model',
    'type': 'object',
}

```

You can use this approach to e.g. define behavior for Pandas or Numpy types.
#### Using `GetPydanticSchema` to reduce boilerplate[Â¶](https://docs.pydantic.dev/latest/concepts/types/#using-getpydanticschema-to-reduce-boilerplate)
API Documentation
[`pydantic.types.GetPydanticSchema`](https://docs.pydantic.dev/latest/api/types/#pydantic.types.GetPydanticSchema)  

You may notice that the above examples where we create a marker class require a good amount of boilerplate. For many simple cases you can greatly minimize this by using `pydantic.GetPydanticSchema`:
```
fromtypingimport Annotated

frompydantic_coreimport core_schema

frompydanticimport BaseModel, GetPydanticSchema


classModel(BaseModel):
    y: Annotated[
        str,
        GetPydanticSchema(
            lambda tp, handler: core_schema.no_info_after_validator_function(
                lambda x: x * 2, handler(tp)
            )
        ),
    ]


assert Model(y='ab').y == 'abab'

```

#### Summary[Â¶](https://docs.pydantic.dev/latest/concepts/types/#summary)
Let's recap:
  1. Pydantic provides high level hooks to customize types via `Annotated` like `AfterValidator` and `Field`. Use these when possible.
  2. Under the hood these use `pydantic-core` to customize validation, and you can hook into that directly using `GetPydanticSchema` or a marker class with `__get_pydantic_core_schema__`.
  3. If you really want a custom type you can implement `__get_pydantic_core_schema__` on the type itself.


### Handling custom generic classes[Â¶](https://docs.pydantic.dev/latest/concepts/types/#handling-custom-generic-classes)
Warning
This is an advanced technique that you might not need in the beginning. In most of the cases you will probably be fine with standard Pydantic models.
You can use `__get_pydantic_core_schema__`.
If the Generic class that you are using as a sub-type has a classmethod `__get_pydantic_core_schema__`, you don't need to use [`arbitrary_types_allowed`](https://docs.pydantic.dev/latest/api/config/#pydantic.config.ConfigDict.arbitrary_types_allowed) for it to work.
Because the `source_type` parameter is not the same as the `cls` parameter, you can use `typing.get_args` (or `typing_extensions.get_args`) to extract the generic parameters. Then you can use the `handler` to generate a schema for them by calling `handler.generate_schema`. Note that we do not do something like `handler(get_args(source_type)[0])` because we want to generate an unrelated schema for that generic parameter, not one that is influenced by the current context of `Annotated` metadata and such. This is less important for custom types, but crucial for annotated metadata that modifies schema building.
[Python 3.9 and above](https://docs.pydantic.dev/latest/concepts/types/#__tabbed_6_1)[Python 3.10 and above](https://docs.pydantic.dev/latest/concepts/types/#__tabbed_6_2)
```
fromdataclassesimport dataclass
fromtypingimport Any, Generic, TypeVar

frompydantic_coreimport CoreSchema, core_schema
fromtyping_extensionsimport get_args, get_origin

frompydanticimport (
    BaseModel,
    GetCoreSchemaHandler,
    ValidationError,
    ValidatorFunctionWrapHandler,
)

ItemType = TypeVar('ItemType')


# This is not a pydantic model, it's an arbitrary generic class
@dataclass
classOwner(Generic[ItemType]):
    name: str
    item: ItemType

    @classmethod
    def__get_pydantic_core_schema__(
        cls, source_type: Any, handler: GetCoreSchemaHandler
    ) -> CoreSchema:
        origin = get_origin(source_type)
        if origin is None:  # used as `x: Owner` without params
            origin = source_type
            item_tp = Any
        else:
            item_tp = get_args(source_type)[0]
        # both calling handler(...) and handler.generate_schema(...)
        # would work, but prefer the latter for conceptual and consistency reasons
        item_schema = handler.generate_schema(item_tp)

        defval_item(
            v: Owner[Any], handler: ValidatorFunctionWrapHandler
        ) -> Owner[Any]:
            v.item = handler(v.item)
            return v

        python_schema = core_schema.chain_schema(
            # `chain_schema` means do the following steps in order:
            [
                # Ensure the value is an instance of Owner
                core_schema.is_instance_schema(cls),
                # Use the item_schema to validate `items`
                core_schema.no_info_wrap_validator_function(
                    val_item, item_schema
                ),
            ]
        )

        return core_schema.json_or_python_schema(
            # for JSON accept an object with name and item keys
            json_schema=core_schema.chain_schema(
                [
                    core_schema.typed_dict_schema(
                        {
                            'name': core_schema.typed_dict_field(
                                core_schema.str_schema()
                            ),
                            'item': core_schema.typed_dict_field(item_schema),
                        }
                    ),
                    # after validating the json data convert it to python
                    core_schema.no_info_before_validator_function(
                        lambda data: Owner(
                            name=data['name'], item=data['item']
                        ),
                        # note that we reuse the same schema here as below
                        python_schema,
                    ),
                ]
            ),
            python_schema=python_schema,
        )


classCar(BaseModel):
    color: str


classHouse(BaseModel):
    rooms: int


classModel(BaseModel):
    car_owner: Owner[Car]
    home_owner: Owner[House]


model = Model(
    car_owner=Owner(name='John', item=Car(color='black')),
    home_owner=Owner(name='James', item=House(rooms=3)),
)
print(model)
"""
car_owner=Owner(name='John', item=Car(color='black')) home_owner=Owner(name='James', item=House(rooms=3))
"""

try:
    # If the values of the sub-types are invalid, we get an error
    Model(
        car_owner=Owner(name='John', item=House(rooms=3)),
        home_owner=Owner(name='James', item=Car(color='black')),
    )
except ValidationError as e:
    print(e)
"""
    2 validation errors for Model
    wine
      Input should be a valid number, unable to parse string as a number [type=float_parsing, input_value='Kinda good', input_type=str]
    cheese
      Input should be a valid boolean, unable to interpret input [type=bool_parsing, input_value='yeah', input_type=str]
    """

# Similarly with JSON
model = Model.model_validate_json(
    '{"car_owner":{"name":"John","item":{"color":"black"}},"home_owner":{"name":"James","item":{"rooms":3}}}'
)
print(model)
"""
car_owner=Owner(name='John', item=Car(color='black')) home_owner=Owner(name='James', item=House(rooms=3))
"""

try:
    Model.model_validate_json(
        '{"car_owner":{"name":"John","item":{"rooms":3}},"home_owner":{"name":"James","item":{"color":"black"}}}'
    )
except ValidationError as e:
    print(e)
"""
    2 validation errors for Model
    car_owner.item.color
      Field required [type=missing, input_value={'rooms': 3}, input_type=dict]
    home_owner.item.rooms
      Field required [type=missing, input_value={'color': 'black'}, input_type=dict]
    """

```

```
fromdataclassesimport dataclass
fromtypingimport Any, Generic, TypeVar

frompydantic_coreimport CoreSchema, core_schema
fromtypingimport get_args, get_origin

frompydanticimport (
    BaseModel,
    GetCoreSchemaHandler,
    ValidationError,
    ValidatorFunctionWrapHandler,
)

ItemType = TypeVar('ItemType')


# This is not a pydantic model, it's an arbitrary generic class
@dataclass
classOwner(Generic[ItemType]):
    name: str
    item: ItemType

    @classmethod
    def__get_pydantic_core_schema__(
        cls, source_type: Any, handler: GetCoreSchemaHandler
    ) -> CoreSchema:
        origin = get_origin(source_type)
        if origin is None:  # used as `x: Owner` without params
            origin = source_type
            item_tp = Any
        else:
            item_tp = get_args(source_type)[0]
        # both calling handler(...) and handler.generate_schema(...)
        # would work, but prefer the latter for conceptual and consistency reasons
        item_schema = handler.generate_schema(item_tp)

        defval_item(
            v: Owner[Any], handler: ValidatorFunctionWrapHandler
        ) -> Owner[Any]:
            v.item = handler(v.item)
            return v

        python_schema = core_schema.chain_schema(
            # `chain_schema` means do the following steps in order:
            [
                # Ensure the value is an instance of Owner
                core_schema.is_instance_schema(cls),
                # Use the item_schema to validate `items`
                core_schema.no_info_wrap_validator_function(
                    val_item, item_schema
                ),
            ]
        )

        return core_schema.json_or_python_schema(
            # for JSON accept an object with name and item keys
            json_schema=core_schema.chain_schema(
                [
                    core_schema.typed_dict_schema(
                        {
                            'name': core_schema.typed_dict_field(
                                core_schema.str_schema()
                            ),
                            'item': core_schema.typed_dict_field(item_schema),
                        }
                    ),
                    # after validating the json data convert it to python
                    core_schema.no_info_before_validator_function(
                        lambda data: Owner(
                            name=data['name'], item=data['item']
                        ),
                        # note that we reuse the same schema here as below
                        python_schema,
                    ),
                ]
            ),
            python_schema=python_schema,
        )


classCar(BaseModel):
    color: str


classHouse(BaseModel):
    rooms: int


classModel(BaseModel):
    car_owner: Owner[Car]
    home_owner: Owner[House]


model = Model(
    car_owner=Owner(name='John', item=Car(color='black')),
    home_owner=Owner(name='James', item=House(rooms=3)),
)
print(model)
"""
car_owner=Owner(name='John', item=Car(color='black')) home_owner=Owner(name='James', item=House(rooms=3))
"""

try:
    # If the values of the sub-types are invalid, we get an error
    Model(
        car_owner=Owner(name='John', item=House(rooms=3)),
        home_owner=Owner(name='James', item=Car(color='black')),
    )
except ValidationError as e:
    print(e)
"""
    2 validation errors for Model
    wine
      Input should be a valid number, unable to parse string as a number [type=float_parsing, input_value='Kinda good', input_type=str]
    cheese
      Input should be a valid boolean, unable to interpret input [type=bool_parsing, input_value='yeah', input_type=str]
    """

# Similarly with JSON
model = Model.model_validate_json(
    '{"car_owner":{"name":"John","item":{"color":"black"}},"home_owner":{"name":"James","item":{"rooms":3}}}'
)
print(model)
"""
car_owner=Owner(name='John', item=Car(color='black')) home_owner=Owner(name='James', item=House(rooms=3))
"""

try:
    Model.model_validate_json(
        '{"car_owner":{"name":"John","item":{"rooms":3}},"home_owner":{"name":"James","item":{"color":"black"}}}'
    )
except ValidationError as e:
    print(e)
"""
    2 validation errors for Model
    car_owner.item.color
      Field required [type=missing, input_value={'rooms': 3}, input_type=dict]
    home_owner.item.rooms
      Field required [type=missing, input_value={'color': 'black'}, input_type=dict]
    """

```

#### Generic containers[Â¶](https://docs.pydantic.dev/latest/concepts/types/#generic-containers)
The same idea can be applied to create generic container types, like a custom `Sequence` type:
[Python 3.9 and above](https://docs.pydantic.dev/latest/concepts/types/#__tabbed_7_1)[Python 3.10 and above](https://docs.pydantic.dev/latest/concepts/types/#__tabbed_7_2)
```
fromcollections.abcimport Sequence
fromtypingimport Any, TypeVar

frompydantic_coreimport ValidationError, core_schema
fromtyping_extensionsimport get_args

frompydanticimport BaseModel, GetCoreSchemaHandler

T = TypeVar('T')


classMySequence(Sequence[T]):
    def__init__(self, v: Sequence[T]):
        self.v = v

    def__getitem__(self, i):
        return self.v[i]

    def__len__(self):
        return len(self.v)

    @classmethod
    def__get_pydantic_core_schema__(
        cls, source: Any, handler: GetCoreSchemaHandler
    ) -> core_schema.CoreSchema:
        instance_schema = core_schema.is_instance_schema(cls)

        args = get_args(source)
        if args:
            # replace the type and rely on Pydantic to generate the right schema
            # for `Sequence`
            sequence_t_schema = handler.generate_schema(Sequence[args[0]])
        else:
            sequence_t_schema = handler.generate_schema(Sequence)

        non_instance_schema = core_schema.no_info_after_validator_function(
            MySequence, sequence_t_schema
        )
        return core_schema.union_schema([instance_schema, non_instance_schema])


classM(BaseModel):
    model_config = dict(validate_default=True)

    s1: MySequence = [3]


m = M()
print(m)
#> s1=<__main__.MySequence object at 0x0123456789ab>
print(m.s1.v)
#> [3]


classM(BaseModel):
    s1: MySequence[int]


M(s1=[1])
try:
    M(s1=['a'])
except ValidationError as exc:
    print(exc)
"""
    2 validation errors for M
    s1.is-instance[MySequence]
      Input should be an instance of MySequence [type=is_instance_of, input_value=['a'], input_type=list]
    s1.function-after[MySequence(), json-or-python[json=list[int],python=chain[is-instance[Sequence],function-wrap[sequence_validator()]]]].0
      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='a', input_type=str]
    """

```

```
fromcollections.abcimport Sequence
fromtypingimport Any, TypeVar

frompydantic_coreimport ValidationError, core_schema
fromtypingimport get_args

frompydanticimport BaseModel, GetCoreSchemaHandler

T = TypeVar('T')


classMySequence(Sequence[T]):
    def__init__(self, v: Sequence[T]):
        self.v = v

    def__getitem__(self, i):
        return self.v[i]

    def__len__(self):
        return len(self.v)

    @classmethod
    def__get_pydantic_core_schema__(
        cls, source: Any, handler: GetCoreSchemaHandler
    ) -> core_schema.CoreSchema:
        instance_schema = core_schema.is_instance_schema(cls)

        args = get_args(source)
        if args:
            # replace the type and rely on Pydantic to generate the right schema
            # for `Sequence`
            sequence_t_schema = handler.generate_schema(Sequence[args[0]])
        else:
            sequence_t_schema = handler.generate_schema(Sequence)

        non_instance_schema = core_schema.no_info_after_validator_function(
            MySequence, sequence_t_schema
        )
        return core_schema.union_schema([instance_schema, non_instance_schema])


classM(BaseModel):
    model_config = dict(validate_default=True)

    s1: MySequence = [3]


m = M()
print(m)
#> s1=<__main__.MySequence object at 0x0123456789ab>
print(m.s1.v)
#> [3]


classM(BaseModel):
    s1: MySequence[int]


M(s1=[1])
try:
    M(s1=['a'])
except ValidationError as exc:
    print(exc)
"""
    2 validation errors for M
    s1.is-instance[MySequence]
      Input should be an instance of MySequence [type=is_instance_of, input_value=['a'], input_type=list]
    s1.function-after[MySequence(), json-or-python[json=list[int],python=chain[is-instance[Sequence],function-wrap[sequence_validator()]]]].0
      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='a', input_type=str]
    """

```

### Access to field name[Â¶](https://docs.pydantic.dev/latest/concepts/types/#access-to-field-name)
Note
This was not possible with Pydantic V2 to V2.3, it was 
As of Pydantic V2.4, you can access the field name via the `handler.field_name` within `__get_pydantic_core_schema__` and thereby set the field name which will be available from `info.field_name`.
```
fromtypingimport Any

frompydantic_coreimport core_schema

frompydanticimport BaseModel, GetCoreSchemaHandler, ValidationInfo


classCustomType:
"""Custom type that stores the field it was used in."""

    def__init__(self, value: int, field_name: str):
        self.value = value
        self.field_name = field_name

    def__repr__(self):
        return f'CustomType<{self.value}{self.field_name!r}>'

    @classmethod
    defvalidate(cls, value: int, info: ValidationInfo):
        return cls(value, info.field_name)

    @classmethod
    def__get_pydantic_core_schema__(
        cls, source_type: Any, handler: GetCoreSchemaHandler
    ) -> core_schema.CoreSchema:
        return core_schema.with_info_after_validator_function(
            cls.validate, handler(int)
        )


classMyModel(BaseModel):
    my_field: CustomType


m = MyModel(my_field=1)
print(m.my_field)
#> CustomType<1 'my_field'>

```

You can also access `field_name` from the markers used with `Annotated`, like [`AfterValidator`](https://docs.pydantic.dev/latest/api/functional_validators/#pydantic.functional_validators.AfterValidator).
```
fromtypingimport Annotated

frompydanticimport AfterValidator, BaseModel, ValidationInfo


defmy_validators(value: int, info: ValidationInfo):
    return f'<{value}{info.field_name!r}>'


classMyModel(BaseModel):
    my_field: Annotated[int, AfterValidator(my_validators)]


m = MyModel(my_field=1)
print(m.my_field)
#> <1 'my_field'>

```

Was this page helpful? 
Thanks for your feedback! 
Thanks for your feedback! 
